{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05d8d3e3",
   "metadata": {},
   "source": [
    "## 5 Challenge Exercises\n",
    "\n",
    "Create a dictionary mapping airport codes to locations\n",
    "\n",
    "Practice indexing and slicing on a list of your hobbies\n",
    "\n",
    "Try removing duplicates from a messy list with a set\n",
    "\n",
    "Search for an item in a tuple using a for loop\n",
    "\n",
    "Time membership checks on dict vs list with a large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ef4ae1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'New York': 'JFK', 'Los Angeles': 'LAX', 'Chicago': 'ORD', 'Dallas': 'DFW', 'Denver': 'DEN'}\n",
      "New York\n",
      "New York\n"
     ]
    }
   ],
   "source": [
    "### Create a dictionary mapping airport codes to locations\n",
    "\n",
    "airport_codes = {\n",
    "    'JFK': 'New York',\n",
    "    'LAX': 'Los Angeles',\n",
    "    'ORD': 'Chicago',\n",
    "    'DFW': 'Dallas',\n",
    "    'DEN': 'Denver'\n",
    "}\n",
    "\n",
    "# Create a dictionary mapping locations to airport codes\n",
    "location_codes = {location: code for code, location in airport_codes.items()}\n",
    "\n",
    "print(location_codes)\n",
    "\n",
    "# get the value using [] operator.\n",
    "print(airport_codes['JFK'])\n",
    "\n",
    "# get the value using get() method.\n",
    "print(airport_codes.get('JFK'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8fc9f35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "football\n",
      "swimming\n",
      "reading\n",
      "biking\n",
      "coding\n",
      "running\n",
      "cooking\n",
      "['football', 'reading', 'coding', 'cooking', 'traveling', 'hiking', 'gaming', 'running', 'biking']\n",
      "['biking', 'running', 'gaming', 'hiking', 'traveling', 'cooking', 'coding', 'reading', 'football']\n",
      "['football', 'coding', 'traveling', 'gaming', 'biking']\n",
      "['football', 'swimming', 'coding', 'cooking', 'traveling', 'hiking', 'gaming', 'running', 'biking']\n"
     ]
    }
   ],
   "source": [
    "### Practice indexing and slicing on a list of your hobbies\n",
    "\n",
    "\n",
    "hobbies = ['football', 'reading', 'coding', 'cooking', 'traveling', 'hiking', 'gaming', 'running', 'biking', 'swimming']\n",
    "\n",
    "# What is the first hobby in the list?\n",
    "print(hobbies[0])\n",
    "\n",
    "# What is the last hobby in the list?\n",
    "print(hobbies[-1])\n",
    "\n",
    "# What is the second hobby in the list?\n",
    "print(hobbies[1])\n",
    "\n",
    "# What is the second last hobby in the list?\n",
    "print(hobbies[-2])\n",
    "\n",
    "# What is the third hobby in the list?\n",
    "print(hobbies[2])\n",
    "\n",
    "# What is the third last hobby in the list?\n",
    "print(hobbies[-3])\n",
    "\n",
    "# What is the fourth hobby in the list?\n",
    "print(hobbies[3])\n",
    "\n",
    "# remove the last hobby in the list\n",
    "hobbies.pop()\n",
    "print(hobbies)\n",
    "\n",
    "# print the list in reverse order\n",
    "print(hobbies[::-1])\n",
    "\n",
    "# print the every alternative hobby in the list\n",
    "print(hobbies[::2])\n",
    "\n",
    "# replace the second hobby in the list with 'swimming'\n",
    "hobbies[1] = 'swimming'\n",
    "print(hobbies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7293421b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reading', 'traveling', 'cooking', 'swimming'}\n"
     ]
    }
   ],
   "source": [
    "### Try removing duplicates from a messy list with a set\n",
    "\n",
    "messy_list = ['swimming', 'reading', 'swimming', 'traveling', 'reading', 'cooking', 'traveling', 'cooking', 'swimming', 'reading', 'traveling', 'cooking', 'swimming', 'reading', 'traveling', 'cooking', 'swimming', 'reading', 'traveling', 'cooking', 'swimming', 'reading', 'traveling',]\n",
    "\n",
    "# remove duplicates\n",
    "unique_set = set(messy_list )\n",
    "\n",
    "print(hobbies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "492103c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create a messy list\n",
    "messy_list = [1, 2, 2, 3, 4, 4, 5, 5, 5]\n",
    "\n",
    "# Step 2: Convert the list to a set to remove duplicates\n",
    "unique_set = set(messy_list)\n",
    "\n",
    "# Step 3: Convert the set back to a list (if needed)\n",
    "unique_list = list(unique_set)\n",
    "\n",
    "print(unique_list)  # Output: [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d02f98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cherry is in the tuple.\n"
     ]
    }
   ],
   "source": [
    "### Search for an item in a tuple using a for loop\n",
    "\n",
    "fruits = ('apple', 'banana', 'cherry', 'date', 'fig')\n",
    "\n",
    "# Item to search for\n",
    "search_item = 'cherry'\n",
    "found = False  # Flag to indicate if the item is found\n",
    "\n",
    "# Step 1: Iterate through the tuple\n",
    "for fruit in fruits:\n",
    "    # Step 2: Check if the current fruit matches the search item\n",
    "    if fruit == search_item:\n",
    "        found = True  # Set the flag to True if found\n",
    "        break  # Exit the loop since we found the item\n",
    "\n",
    "# Step 3: Check if the item was found\n",
    "if found:\n",
    "    print(f\"{search_item} is in the tuple.\")\n",
    "else:\n",
    "    print(f\"{search_item} is not in the tuple.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "58c48de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membership check in list: True, Time taken: 0.010148 seconds\n",
      "Membership check in dict: True, Time taken: 0.000094 seconds\n"
     ]
    }
   ],
   "source": [
    "#### Time membership checks on dict vs list with a large dataset\n",
    "\n",
    "import time\n",
    "\n",
    "# Create a large dataset\n",
    "large_list = list(range(1000000))  # A list with 1 million integers\n",
    "large_dict = {i: None for i in range(1000000)}  # A dictionary with 1 million key-value pairs\n",
    "\n",
    "# Item to check for\n",
    "item_to_check = 999999\n",
    "\n",
    "# Time membership check in a list\n",
    "start_time = time.time()\n",
    "is_in_list = item_to_check in large_list\n",
    "end_time = time.time()\n",
    "print(f\"Membership check in list: {is_in_list}, Time taken: {end_time - start_time:.6f} seconds\")\n",
    "\n",
    "# Time membership check in a dictionary\n",
    "start_time = time.time()\n",
    "is_in_dict = item_to_check in large_dict\n",
    "end_time = time.time()\n",
    "print(f\"Membership check in dict: {is_in_dict}, Time taken: {end_time - start_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f3ddd7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membership check in list: True, Time taken: 0.000863 seconds\n",
      "Membership check in set: True, Time taken: 0.000027 seconds\n",
      "Membership check in sorted list: True, Time taken: 0.000056 seconds\n",
      "Membership check in NumPy array: True, Time taken: 0.003095 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import bisect\n",
    "\n",
    "# Create a large dataset\n",
    "large_list = list(range(1000000))  # A list with 1 million integers\n",
    "large_set = set(large_list)          # Convert list to set for faster lookups\n",
    "sorted_list = sorted(large_list)      # Sort the list for binary search\n",
    "item_to_check = 123456                # Item to check for\n",
    "\n",
    "# 1. Direct List Membership Check\n",
    "start_time = time.time()\n",
    "is_in_list = item_to_check in large_list\n",
    "end_time = time.time()\n",
    "print(f\"Membership check in list: {is_in_list}, Time taken: {end_time - start_time:.6f} seconds\")\n",
    "\n",
    "# 2. Using a Set for Membership Check\n",
    "start_time = time.time()\n",
    "is_in_set = item_to_check in large_set\n",
    "end_time = time.time()\n",
    "print(f\"Membership check in set: {is_in_set}, Time taken: {end_time - start_time:.6f} seconds\")\n",
    "\n",
    "# 3. Binary Search on a Sorted List\n",
    "start_time = time.time()\n",
    "index = bisect.bisect_left(sorted_list, item_to_check)\n",
    "is_in_sorted_list = index < len(sorted_list) and sorted_list[index] == item_to_check\n",
    "end_time = time.time()\n",
    "print(f\"Membership check in sorted list: {is_in_sorted_list}, Time taken: {end_time - start_time:.6f} seconds\")\n",
    "\n",
    "# 4. Using NumPy for Membership Check\n",
    "np_array = np.array(large_list)  # Create a NumPy array\n",
    "start_time = time.time()\n",
    "found_in_numpy = np.isin(item_to_check, np_array)\n",
    "end_time = time.time()\n",
    "print(f\"Membership check in NumPy array: {found_in_numpy}, Time taken: {end_time - start_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f0f4a52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALYZING FOR REPETITIONS AND PROGRESSION:\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Apple (2020-Present):\n",
      "  - 'infrastructure': 5 times\n",
      "  - 'Designed': 4 times\n",
      "  - 'Led': 4 times\n",
      "  - 'Established': 3 times\n",
      "  - 'Architected': 3 times\n",
      "\n",
      "Ten-X (2019):\n",
      "  - 'Implemented': 4 times\n",
      "  - 'automated': 4 times\n",
      "  - 'Designed': 3 times\n",
      "  - 'Developed': 3 times\n",
      "  - 'Established': 2 times\n",
      "\n",
      "Exaalgia (2015-2017):\n",
      "  - 'Designed': 4 times\n",
      "  - 'Implemented': 4 times\n",
      "  - 'automated': 3 times\n",
      "  - 'infrastructure': 3 times\n",
      "  - 'Established': 2 times\n",
      "\n",
      "Meridian (2013-2015):\n",
      "  - 'Implemented': 3 times\n",
      "  - 'infrastructure': 3 times\n",
      "  - 'Designed': 1 times\n",
      "  - 'Established': 1 times\n",
      "  - 'Developed': 1 times\n",
      "\n",
      "Aconix (2012-2013):\n",
      "  - 'Implemented': 3 times\n",
      "  - 'Developed': 3 times\n",
      "  - 'Designed': 2 times\n",
      "  - 'monitoring': 1 times\n",
      "\n",
      "======================================================================\n",
      "\n",
      "REPETITIVE CONCEPTS ACROSS ROLES:\n",
      "\n",
      "⚠️  'CI/CD Pipelines' appears in: Apple, Ten-X, Exaalgia\n",
      "⚠️  'Kubernetes' appears in: Apple, Ten-X, Exaalgia\n",
      "⚠️  'Infrastructure Automation' appears in: Apple, Ten-X, Exaalgia\n",
      "⚠️  'Incident Response' appears in: Apple, Ten-X, Meridian\n",
      "⚠️  'Documentation' appears in: Ten-X, Meridian, Aconix\n",
      "⚠️  'Collaboration' appears in: Apple, Meridian, Aconix\n"
     ]
    }
   ],
   "source": [
    "# Let me analyze the resume content for repetitive phrases and concepts across roles\n",
    "\n",
    "resume_roles = {\n",
    "    \"Apple (2020-Present)\": [\n",
    "        \"Architected and operated mission-critical Kubernetes infrastructure\",\n",
    "        \"Led architectural design and execution of petabyte-scale Solr migration\",\n",
    "        \"Oversee large-scale Hadoop environments\",\n",
    "        \"Architected resource allocation strategies for Spark-based\",\n",
    "        \"Established comprehensive observability infrastructure\",\n",
    "        \"Designed and implemented GitOps workflows\",\n",
    "        \"Deployed advanced monitoring infrastructure\",\n",
    "        \"Led implementation of Zero Trust security architecture\",\n",
    "        \"Embedded DevSecOps practices throughout CI/CD pipelines\",\n",
    "        \"Designed compliance and security frameworks\",\n",
    "        \"Architected observability and usage tracking frameworks\",\n",
    "        \"Led infrastructure cost optimization initiatives\",\n",
    "        \"Established incident response protocols\",\n",
    "        \"Designed comprehensive incident management practices\",\n",
    "        \"Led and mentored infrastructure engineering team\",\n",
    "        \"Established technical hiring practices\",\n",
    "        \"Collaborated with cross-functional stakeholders\",\n",
    "        \"Developed extensive library of reusable Terraform modules\",\n",
    "        \"Streamlined microservices provisioning workflows\",\n",
    "        \"Designed automated customer onboarding solutions\"\n",
    "    ],\n",
    "    \n",
    "    \"Ten-X (2019)\": [\n",
    "        \"Designed and automated end-to-end CI/CD pipelines\",\n",
    "        \"Developed custom pipeline templates\",\n",
    "        \"Implemented automated rollback mechanisms\",\n",
    "        \"Developed extensive infrastructure automation tooling\",\n",
    "        \"Built internal automation frameworks\",\n",
    "        \"Created comprehensive documentation and runbooks\",\n",
    "        \"Automated multi-cloud infrastructure provisioning\",\n",
    "        \"Designed and implemented Kubernetes deployment patterns\",\n",
    "        \"Established container image management practices\",\n",
    "        \"Configured, secured, and maintained enterprise-grade Hadoop clusters\",\n",
    "        \"Implemented cluster capacity planning\",\n",
    "        \"Developed automated cluster health monitoring\",\n",
    "        \"Enhanced system observability\",\n",
    "        \"Established monitoring frameworks\",\n",
    "        \"Designed and implemented SLI/SLO tracking mechanisms\"\n",
    "    ],\n",
    "    \n",
    "    \"Exaalgia (2015-2017)\": [\n",
    "        \"Architected and managed enterprise hybrid cloud infrastructure\",\n",
    "        \"Implemented disaster recovery and business continuity solutions\",\n",
    "        \"Designed network architecture with load balancers\",\n",
    "        \"Established cloud governance frameworks\",\n",
    "        \"Automated Docker container orchestration\",\n",
    "        \"Developed containerization strategies\",\n",
    "        \"Designed Kubernetes cluster architectures\",\n",
    "        \"Implemented Helm chart repositories\",\n",
    "        \"Automated infrastructure provisioning workflows\",\n",
    "        \"Designed and maintained modular, reusable Terraform modules\",\n",
    "        \"Implemented state management strategies for Terraform\",\n",
    "        \"Established infrastructure testing practices\",\n",
    "        \"Implemented comprehensive Jenkins CI/CD pipelines\",\n",
    "        \"Designed pipeline-as-code configurations\",\n",
    "        \"Integrated automated testing frameworks\"\n",
    "    ],\n",
    "    \n",
    "    \"Meridian (2013-2015)\": [\n",
    "        \"Administered production Linux server infrastructure\",\n",
    "        \"Maintained system security posture\",\n",
    "        \"Implemented configuration management practices\",\n",
    "        \"Developed automated backup and recovery procedures\",\n",
    "        \"Provided continuous incident response coverage\",\n",
    "        \"Established incident response runbooks\",\n",
    "        \"Conducted post-incident reviews\",\n",
    "        \"Maintained incident tracking and documentation\",\n",
    "        \"Implemented and maintained critical infrastructure services\",\n",
    "        \"Performed system performance monitoring\",\n",
    "        \"Designed and implemented log management solutions\",\n",
    "        \"Managed user account provisioning\",\n",
    "        \"Collaborated closely with data center teams\",\n",
    "        \"Planned and executed server migration projects\",\n",
    "        \"Responded to hardware failures\",\n",
    "        \"Maintained accurate infrastructure documentation\"\n",
    "    ],\n",
    "    \n",
    "    \"Aconix (2012-2013)\": [\n",
    "        \"Developed and maintained Java/J2EE enterprise applications\",\n",
    "        \"Designed and implemented RESTful APIs\",\n",
    "        \"Developed multi-threaded application components\",\n",
    "        \"Implemented error handling, logging, and monitoring\",\n",
    "        \"Enhanced database query performance\",\n",
    "        \"Designed normalized database schemas\",\n",
    "        \"Implemented database connection pooling\",\n",
    "        \"Conducted application stability improvements\",\n",
    "        \"Participated in code reviews\",\n",
    "        \"Developed unit tests and integration tests\",\n",
    "        \"Collaborated with business analysts\",\n",
    "        \"Contributed to technical documentation\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Check for repeated phrases/concepts\n",
    "print(\"ANALYZING FOR REPETITIONS AND PROGRESSION:\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Common repeated phrases to look for\n",
    "repeated_terms = [\n",
    "    (\"Designed\", 0),\n",
    "    (\"Implemented\", 0),\n",
    "    (\"Established\", 0),\n",
    "    (\"Developed\", 0),\n",
    "    (\"Architected\", 0),\n",
    "    (\"Built\", 0),\n",
    "    (\"Created\", 0),\n",
    "    (\"Led\", 0),\n",
    "    (\"Managed\", 0),\n",
    "    (\"automated\", 0),\n",
    "    (\"monitoring\", 0),\n",
    "    (\"CI/CD\", 0),\n",
    "    (\"Kubernetes\", 0),\n",
    "    (\"infrastructure\", 0),\n",
    "]\n",
    "\n",
    "# Count occurrences\n",
    "for role, bullets in resume_roles.items():\n",
    "    print(f\"\\n{role}:\")\n",
    "    role_counts = {}\n",
    "    for term, _ in repeated_terms:\n",
    "        count = sum(1 for bullet in bullets if term.lower() in bullet.lower())\n",
    "        if count > 0:\n",
    "            role_counts[term] = count\n",
    "    \n",
    "    for term, count in sorted(role_counts.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "        print(f\"  - '{term}': {count} times\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nREPETITIVE CONCEPTS ACROSS ROLES:\\n\")\n",
    "\n",
    "# Check for similar concepts repeated across roles\n",
    "repetitive_concepts = {\n",
    "    \"CI/CD Pipelines\": [\"Apple\", \"Ten-X\", \"Exaalgia\"],\n",
    "    \"Monitoring/Observability\": [\"Apple\", \"Ten-X\"],\n",
    "    \"Kubernetes\": [\"Apple\", \"Ten-X\", \"Exaalgia\"],\n",
    "    \"Terraform\": [\"Apple\", \"Exaalgia\"],\n",
    "    \"Infrastructure Automation\": [\"Apple\", \"Ten-X\", \"Exaalgia\"],\n",
    "    \"Incident Response\": [\"Apple\", \"Ten-X\", \"Meridian\"],\n",
    "    \"Documentation\": [\"Ten-X\", \"Meridian\", \"Aconix\"],\n",
    "    \"Collaboration\": [\"Apple\", \"Meridian\", \"Aconix\"]\n",
    "}\n",
    "\n",
    "for concept, roles in repetitive_concepts.items():\n",
    "    if len(roles) > 2:\n",
    "        print(f\"⚠️  '{concept}' appears in: {', '.join(roles)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
